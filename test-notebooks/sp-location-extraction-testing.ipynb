{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook explores methods for extracting locations related to mentions of taxa.\n",
    "\n",
    "Status: In Development \n",
    "\n",
    "Last Updated: 201904\n",
    "\n",
    "Summary: Using output from the eXtract Dark Data (xDD) (previously named GeoDeepDive) database we are exploring ways to extract information about species/taxa of interest from literature. These efforts are using a list of taxa being studied by the USGS Nonindigenous Aquatic Species Program, but should be applicable to any list of taxanomic names.\n",
    "\n",
    "Inputs:  *Taxa Information (url='https://nas.er.usgs.gov/api/v1/species')\n",
    "        \n",
    "        *xDD processed data, output from \n",
    "        https://github.com/dwief-usgs/app-template-nas\n",
    "\n",
    "Contact: Daniel Wieferich (dwieferich@usgs.gov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import needed packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "#Import Functions\n",
    "def get_species_list(url='https://nas.er.usgs.gov/api/v1/species'):\n",
    "    \"\"\"return list of taxa information for NAS species of interest\n",
    "    ----------\n",
    "    URL : API that returns JSON results of NAS specie taxonomy\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            return r.json()\n",
    "        else:\n",
    "            raise Exception('NAS API URL returning: {}'.format(r.status_code))\n",
    "    except Exception as e:\n",
    "        raise Exception(e)\n",
    "\n",
    "#Keeps rows in pd from being truncated\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "--------------\n",
    "*Import source datasets including list of taxa names (from NAS API) and literature passages from xDD\n",
    "\n",
    "\n",
    "#### Progress\n",
    "--------------\n",
    "-Currently using a set of passages from dam removal exercise for testing while taxa information is being processed by xDD staff\n",
    "\n",
    "-Need to rethink logic behind taxanomic names to process, based on conversations with NAS team.  For example, species 3118 is returning a common name of \"mussel\".  This is currently being processed but should not be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import example passage output from xDD\n",
    "#This will be updated with taxa mentions coming from\n",
    "\n",
    "xdd_export = 'dam_year_river_22h33m_06Nov2018_a4c1766/river-cand-df.csv'\n",
    "xdd_df = pd.read_csv(xdd_export, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a big file, lets make it smaller (5,000 records) for testing purpose\n",
    "xdd_df.shape\n",
    "xdd_df_sub = xdd_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run function to return NAS taxa information as JSON response\n",
    "taxa_r = get_species_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxa_list = []\n",
    "for taxa in taxa_r['results']:\n",
    "    #captures a hybrid based on x of species, only return common name \n",
    "    if ' x ' in taxa['species']:\n",
    "        taxa_list.append({'speciesID': taxa['speciesID'], 'common_name': taxa['common_name']})\n",
    "    #for taxa with species = sp., return genus and common name\n",
    "    elif 'sp.' in taxa['species']:\n",
    "        taxa_list.append({'speciesID': taxa['speciesID'], 'genus': taxa['genus'], 'common_name': taxa['common_name']})\n",
    "    #for everything else return scientific name (including subspecies and variety as available) and common name\n",
    "    else:\n",
    "        sci_name = (taxa['genus']+' '+taxa['species'] + ' '+ taxa['subspecies'] + ' ' + taxa['variety']).strip()\n",
    "        taxa_list.append({'speciesID': taxa['speciesID'], 'sci_name': sci_name, 'common_name': taxa['common_name']})\n",
    "\n",
    "taxa_df = pd.DataFrame(taxa_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "--------------\n",
    "*For each passage identify mentions of species and explore ways to extract location information\n",
    "\n",
    "\n",
    "#### Progress\n",
    "--------------\n",
    "-starting with basic use of NER tags within close proximity\n",
    "\n",
    "-we have efforts in progress to create NER tags specific to rivers (using SpaCy), to better understand and extract river mentions\n",
    "\n",
    "-first pass on running this with full 2 million records and full taxa list did not complete in a full 8 hr work day... need to incorporate a mode of doing batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "mention = []\n",
    "for row_xdd in xdd_df_sub.itertuples():\n",
    "    for row_taxa in taxa_df.itertuples():\n",
    "        speciesID = row_taxa.speciesID\n",
    "        if str(row_taxa.sci_name)!= 'nan' and str(row_taxa.sci_name) in ast.literal_eval(row_xdd.passage):\n",
    "            #print (str(speciesID)+': '+str(row_river.passage))\n",
    "            #record speciesID, passageID, passage\n",
    "            mention.append({'species_id': speciesID, 'taxa':row_taxa.sci_name, 'passage': row_river.passage, 'docid':row_xdd.docid, 'ner': row_xdd.ner, 'sentid':row_xdd.sentid})\n",
    "        #if str(row_taxa.genus)!= 'nan' and str(row_taxa.genus) in ast.literal_eval(row_river.passage):\n",
    "        #    mention.append({'species_id': speciesID, 'taxa':row_taxa.genus, 'passage': row_xdd.passage, 'docid':row_xdd.docid, 'ner': row_xdd.ner, 'sentid':row_xdd.sentid})\n",
    "            #print (row_taxa.genus)\n",
    "            #print (str(speciesID)+': '+str(row_river.passage))\n",
    "        #if str(row_taxa.common_name)!= 'nan' and str(row_taxa.common_name)!='' and str(row_taxa.common_name) in ast.literal_eval(row_river.passage):\n",
    "        #    mention.append({'species_id': speciesID, 'taxa':row_taxa.common_name, 'passage': row_xdd.passage, 'docid':row_xdd.docid, 'ner': row_xdd.ner, 'sentid':row_xdd.sentid})\n",
    "            #print (row_taxa.common_name)\n",
    "            #print (str(speciesID)+': '+str(row_xdd.passage))\n",
    "\n",
    "mention_df = pd.DataFrame(mention)\n",
    "mention_df.to_csv(\"./mention_df_sciname.csv\", sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mention_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generally , there is no gradient in salinity between the lower lakes and the Coorong ; instead , there is an abrupt transition between fresh and brackish/marine salinities . The impact that changes in such physiochemical signals have on the upstream movements of these species is uncertain . In the Murray-Darling Basin , connectivity between the Southern Ocean , estuary and the freshwater environments of the lower lakes and Murray River is imperative for at least ﬁve species of diadromous ﬁshes , namely anadromous Short-headed and Pouched Lamprey -LRB- Mordacia mordax and Geotria australis -RRB- and catadromous Common Galaxias -LRB- Galaxias maculatus -RRB- , Congolli and Short-ﬁnned Eel -LRB- Anguilla australis -RRB- .\n",
      "[[14, 14], [50, 51], [56, 57], [69, 70], [92, 92], [109, 109]]\n",
      "The impact that changes in such physiochemical signals have on the upstream movements of these species is uncertain . In the Murray-Darling Basin , connectivity between the Southern Ocean , estuary and the freshwater environments of the lower lakes and Murray River is imperative for at least ﬁve species of diadromous ﬁshes , namely anadromous Short-headed and Pouched Lamprey -LRB- Mordacia mordax and Geotria australis -RRB- and catadromous Common Galaxias -LRB- Galaxias maculatus -RRB- , Congolli and Short-ﬁnned Eel -LRB- Anguilla australis -RRB- . The original intent of the Sea to Hume Dam Fish Passage programme was to construct a number of experimen - tal ﬁshways at the Murray barrages use assessment results to inform additional ﬁshways in the region .\n",
      "[[21, 22], [27, 28], [40, 41], [63, 63], [80, 80]]\n",
      "In the Murray-Darling Basin , connectivity between the Southern Ocean , estuary and the freshwater environments of the lower lakes and Murray River is imperative for at least ﬁve species of diadromous ﬁshes , namely anadromous Short-headed and Pouched Lamprey -LRB- Mordacia mordax and Geotria australis -RRB- and catadromous Common Galaxias -LRB- Galaxias maculatus -RRB- , Congolli and Short-ﬁnned Eel -LRB- Anguilla australis -RRB- . The original intent of the Sea to Hume Dam Fish Passage programme was to construct a number of experimen - tal ﬁshways at the Murray barrages use assessment results to inform additional ﬁshways in the region . The need for several additional ﬁshways at the Murray barrages was seen as a priority in South Australian Government 's Coorong , Lower Lakes and Murray Mouth Long Term Plan .\n",
      "[[2, 3], [8, 9], [21, 22], [44, 44], [61, 61]]\n"
     ]
    }
   ],
   "source": [
    "#List Pairs of Species / Locations using NER tags\n",
    "\n",
    "import itertools\n",
    "def intervals_extract(iterable): \n",
    "    iterable = sorted(set(iterable)) \n",
    "    for key, group in itertools.groupby(enumerate(iterable), \n",
    "    lambda t: t[1] - t[0]): \n",
    "        group = list(group) \n",
    "        yield [group[0][1], group[-1][1]] \n",
    "\n",
    "\n",
    "import ast\n",
    "\n",
    "for row_xdd in xdd_df_sub.itertuples():\n",
    "    passage = list(ast.literal_eval(row_xdd.passage))\n",
    "    passage_str = ' '.join(word for word in passage)\n",
    "    ner = list(ast.literal_eval(row_xdd.ner))\n",
    "    docid = row_xdd.docid\n",
    "    sentid = row_xdd.sentid\n",
    "    if 'Anguilla' in passage_str:\n",
    "        \n",
    "        print (passage_str)\n",
    "        index_locations = list([i for i,s in enumerate(ner) if 'LOCATION' in s])\n",
    "        location_intervals = list(intervals_extract(index_locations))\n",
    "        #index_taxa = list([i for i,s in enumerate(passage) if 'Anguilla' in s])\n",
    "        print (location_intervals)\n",
    "        #for i in index_locations:\n",
    "        #    p = passage[i]\n",
    "        #    n = ner[i]\n",
    "        #    print (sentid + ': ' + str(i)+ ': '+ p)\n",
    "        #    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
